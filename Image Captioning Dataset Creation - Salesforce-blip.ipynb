{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6e67527-eb6c-41ca-840c-9cdfc9b4cfd9",
   "metadata": {},
   "source": [
    "### Method 1 (Sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e70ef62-88b7-4102-a0f4-bc1f26a1d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from PIL import Image\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2efc8bc7-45ab-479b-b562-f4c2760aa545",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"image-to-text\", model=\"Salesforce/blip-image-captioning-large\", device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49bc68f4-fef1-40fe-954f-0c89cfbdc4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_caption(image_path):\n",
    "    \"\"\"\n",
    "    Generate a caption for an image.\n",
    "    \"\"\"\n",
    "    # Open the image\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    # Generate the caption\n",
    "    result = pipe(img, max_new_tokens=75)\n",
    "    return result[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bec4542-2d5b-4dc4-a2cf-4b499475b236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(data, filename='captions.csv'):\n",
    "    \"\"\"\n",
    "    Save data to a CSV file.\n",
    "    \"\"\"\n",
    "    fieldnames = ['Image Path', 'Caption']\n",
    "    try:\n",
    "        with open(filename, mode='w') as file:\n",
    "            writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for row in data:\n",
    "                writer.writerow(row)\n",
    "    except FileExistsError:\n",
    "        print(f\"File {filename} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0223418f-b135-4b0a-9de5-be52e03a27db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(directory='images'):\n",
    "    \"\"\"\n",
    "    Process all images in a directory and save captions to a CSV file.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for filename in tqdm(os.listdir(directory), desc=\"Processing Images\"):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            caption = generate_caption(image_path)\n",
    "            data.append({'Image Path': image_path, 'Caption': caption})\n",
    "    \n",
    "    save_to_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbd4655-29e8-4270-8fae-d018af965116",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  52%|████████████████████████████████████████████████████████████████████████████▎                                                                     | 116/222 [00:35<00:33,  3.17it/s]"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    process_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cea965-416d-4309-9afd-08c382666b78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e052333-574e-44c1-bcef-167eff4dfbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is avalible!\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is avalible!\")\n",
    "else:\n",
    "    print(\"CUDA is not available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fce59ae-0374-4ce0-8da8-9edff404867c",
   "metadata": {},
   "source": [
    "### Method 2 (via Datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79acf9f2-740e-48c3-b51f-753735987e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3a697566e4493590bd73db8f5f21f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/221 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['path', 'caption'],\n",
      "    num_rows: 1\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import pipeline\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the image-to-text pipeline\n",
    "pipe = pipeline(\"image-to-text\", model=\"Salesforce/blip-image-captioning-large\", device='cuda')\n",
    "\n",
    "def generate_caption(image_path):\n",
    "    \"\"\"\n",
    "    Generate a caption for an image.\n",
    "    \"\"\"\n",
    "    # Open the image\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    # Generate the caption\n",
    "    result = pipe(img, max_new_tokens=75)\n",
    "    return result[0]['generated_text']\n",
    "\n",
    "def process_image_dataset(dataset):\n",
    "    \"\"\"\n",
    "    Process a dataset of images and generate captions.\n",
    "    \"\"\"\n",
    "    def gen_captions(example):\n",
    "        example['caption'] = generate_caption(example['path'])\n",
    "        return example\n",
    "    \n",
    "    processed_dataset = dataset.map(gen_captions)\n",
    "\n",
    "    print(processed_dataset.take(1))\n",
    "    \n",
    "    return processed_dataset\n",
    "\n",
    "def save_to_csv(data, filename='metadata.csv'):\n",
    "    \"\"\"\n",
    "    Save data to a CSV file.\n",
    "    \"\"\"\n",
    "    fieldnames = ['file_name', 'text']\n",
    "    try:\n",
    "        with open(filename, mode='w') as file:\n",
    "            writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for row in data:\n",
    "                writer.writerow(row)\n",
    "    except FileExistsError:\n",
    "        print(f\"File {filename} already exists.\")\n",
    "\n",
    "def process_images(directory='images'):\n",
    "    \"\"\"\n",
    "    Process all images in a directory and save captions to a CSV file.\n",
    "    \"\"\"\n",
    "    # Create a dataset from the directory\n",
    "    dataset = Dataset.from_pandas(pd.DataFrame({\n",
    "        'path': [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    }))\n",
    "    \n",
    "    # Process the dataset\n",
    "    processed_dataset = process_image_dataset(dataset)\n",
    "\n",
    "    \n",
    "    # Convert the processed dataset back to a list of dicts\n",
    "    data = [{'file_name': item['path'], 'text': item['caption']} for item in processed_dataset]\n",
    "    \n",
    "    # Save to CSV\n",
    "    save_to_csv(data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_images()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31946ec7-a668-45a2-a08b-c132b2f11f42",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BaseEnv",
   "language": "python",
   "name": "baseenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
